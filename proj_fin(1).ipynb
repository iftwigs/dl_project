{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект по Deep Learning: Sentiment Analysis c предобученной моделью"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача проекта — с помощью transfer learning BERT'a получить модель для оценки тональности отзывов на различные авиакомпании. Изначально предполагалось использовать датасет из англоязычных твитов с меншнами авиакомпаний с тремя типами оценок — негативной, положительной и нейтральной, однако в процессе реализации обнаружилась ошибка, о которой подробнее напишу в итогах, и поэтому данные пришлось заменить на другие, в которых только два класса.\n",
    "\n",
    "Из других работ по теме нашлись туториалы по transfer learning для оценки тональности от fast.ai (например https://docs.fast.ai/tutorial.text.html), показался интересным их формат данных, получающийся в результате препроцессинга – он добавляет новые служебные токены, например, для обозначения капитализации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80938</td>\n",
       "      <td>@united I'm having issues. Yesterday I rebooke...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10959</td>\n",
       "      <td>@united kinda feel like the $6.99 you charge f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130813</td>\n",
       "      <td>Livid in Vegas, delayed, again&amp;amp; again&amp;amp;...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146589</td>\n",
       "      <td>@united the most annoying man on earth is on m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117579</td>\n",
       "      <td>@united The last 2 weeks I've flown wit u, you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              tweet  label\n",
       "0   80938  @united I'm having issues. Yesterday I rebooke...      0\n",
       "1   10959  @united kinda feel like the $6.99 you charge f...      0\n",
       "2  130813  Livid in Vegas, delayed, again&amp; again&amp;...      0\n",
       "3  146589  @united the most annoying man on earth is on m...      0\n",
       "4  117579  @united The last 2 weeks I've flown wit u, you...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1700\n",
       "0    1700\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>tid_not_to_be_used</th>\n",
       "      <th>airline</th>\n",
       "      <th>tag</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>506248858599710720</td>\n",
       "      <td>SouthWest</td>\n",
       "      <td>iL{o7e82\\Uob</td>\n",
       "      <td>@SouthwestAir get your damn act together. Don'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>506259476341477376</td>\n",
       "      <td>American</td>\n",
       "      <td>iL{o7e82\\Uob</td>\n",
       "      <td>@AmericanAir horrible at responding to emails....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>135</td>\n",
       "      <td>506402253826428928</td>\n",
       "      <td>American</td>\n",
       "      <td>iL{o7e82\\Uob</td>\n",
       "      <td>@AmericanAir hey where is your crew? Flight aa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>159</td>\n",
       "      <td>506438943454158848</td>\n",
       "      <td>United</td>\n",
       "      <td>iL{o7e82\\Uob</td>\n",
       "      <td>Ok come on we are late let's goooo @united</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>182</td>\n",
       "      <td>506455754568904704</td>\n",
       "      <td>American</td>\n",
       "      <td>iL{o7e82\\Uob</td>\n",
       "      <td>@AmericanAir since you are now affiliated with...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   id  tid_not_to_be_used    airline           tag  \\\n",
       "0           1   33  506248858599710720  SouthWest  iL{o7e82\\Uob   \n",
       "1           2   58  506259476341477376   American  iL{o7e82\\Uob   \n",
       "2           3  135  506402253826428928   American  iL{o7e82\\Uob   \n",
       "3           4  159  506438943454158848     United  iL{o7e82\\Uob   \n",
       "4           5  182  506455754568904704   American  iL{o7e82\\Uob   \n",
       "\n",
       "                                               tweet  \n",
       "0  @SouthwestAir get your damn act together. Don'...  \n",
       "1  @AmericanAir horrible at responding to emails....  \n",
       "2  @AmericanAir hey where is your crew? Flight aa...  \n",
       "3         Ok come on we are late let's goooo @united  \n",
       "4  @AmericanAir since you are now affiliated with...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data[['id', 'tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>@SouthwestAir get your damn act together. Don'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>@AmericanAir horrible at responding to emails....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135</td>\n",
       "      <td>@AmericanAir hey where is your crew? Flight aa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159</td>\n",
       "      <td>Ok come on we are late let's goooo @united</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>182</td>\n",
       "      <td>@AmericanAir since you are now affiliated with...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                              tweet\n",
       "0   33  @SouthwestAir get your damn act together. Don'...\n",
       "1   58  @AmericanAir horrible at responding to emails....\n",
       "2  135  @AmericanAir hey where is your crew? Flight aa...\n",
       "3  159         Ok come on we are late let's goooo @united\n",
       "4  182  @AmericanAir since you are now affiliated with..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4555"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве бейзлайна попробуем tf-idf + логистическую регрессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    \n",
    "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.tweet.values\n",
    "y = train_data.label.values\n",
    "\n",
    "X_train, X_valid, y_train, y_valid =\\\n",
    "    train_test_split(X, y, test_size=0.1, random_state=234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = np.array([clean(text) for text in X_train])\n",
    "X_valid_preprocessed = np.array([clean(text) for text in X_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf.fit_transform(X_train_preprocessed)\n",
    "X_valid_tfidf = tfidf.transform(X_valid_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_chart(probs, y_true):\n",
    "\n",
    "    preds = probs[:, 1]\n",
    "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print('AUC: ', roc_auc)\n",
    "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print('Accuracy: ', acc)\n",
    "\n",
    "    plt.plot(fpr, tpr, 'b')\n",
    "    plt.plot()\n",
    "    plt.ylabel('true positives ')\n",
    "    plt.xlabel('false positives ')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = LogisticRegression(random_state=234, max_iter=1000)\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "probs = nb_model.predict_proba(X_valid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8197748917748918\n",
      "Accuracy:  0.7529411764705882\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYTklEQVR4nO3df5BldXnn8fcHEC0V0ZWx1gLGQcVV1pjR6sW4JplxRRcIwpoQBZasKOu4KpJVQ0kKlxjclBLjjzVSSrtSqHFENJU4qyC7awBrEZQxEhRcUiP+YFAXRENhLH+gz/5xTodL0z19ZqbPvX3veb+qbvU5555773Om4T79/XGeb6oKSdJw7TPpACRJk2UikKSBMxFI0sCZCCRp4EwEkjRw+006gN110EEH1YYNGyYdhiRNlS996Uvfr6p1Sz03dYlgw4YNbN++fdJhSNJUSfKt5Z6za0iSBs5EIEkDZyKQpIEzEUjSwJkIJGngeksESS5KckeSry7zfJK8O8mOJDcmeUZfsUiSltdni+Bi4OhdPH8McHj72AK8t8dYJEnL6O0+gqr6XJINuzjlBOBD1dTBvi7JI5M8tqq+21dMkoZpfh62bp10FHtv40Z417tW/30neUPZwcBtI/s722MPSARJttC0Gli/fv1YgpM0nZb60r/66ubnpk3jj2caTMWdxVU1D8wDzM3NuZKOpGVt3Qo33ND89bxg0yY45RTYsmVSUa1tk0wEtwOHjuwf0h6TpN220BJYSAJXXTXhgKbIJBPBNuCMJJcAzwTudnxA0u5aSACj3T+nnDLZmKZNb4kgyUeBzcBBSXYCfwQ8CKCq3gdcBhwL7AB+DLy0r1gkzYaV+v/t/tkzfc4aOnmF5wt4dV+fL2m6dR30NQHsvakYLJY0m3Y1rdMv/fExEUiamKVm+CzwS398TASSJsoZPpNn0TlJGjhbBJJ6tatxgOW6hTReJgJJq2rxF/+uyjts3Oic/7XARCANVF+F2BZ/8Tvou/aZCKSB2tWMnb3hF//0MRFIA7G4BWBNHi1w1pA0EAstgAX2z2uBLQJpjeh78RRbAFqOiUCagEksnmILQMsxEUg9sY6OpoWJQOqJdXQ0LUwEUo/sk9c0MBFIe8HyCZoFJgKJPZ+xY/kEzQITgQZtqfVud4d9/ZoFJgIN2sKArl/oGjITgQbPAV0NnSUmNEjz87B58/1LLkhDZYtAgzM/D694RbO90CUkDZmJQDNhd2b9LAwMX3ihYwISmAi0Ru3udM7dmfXjwLB0fyYCrSl7Op3TL3dpz5kItKY4nVMaPxOBJm60G8ia+dL4mQg0Fl1LMluWQRo/E4HGwpLM0tplIlCvFloCdvlIa5eJQKtutBtotNvHLh9pbeq1xESSo5PckmRHkrOXeH59kiuTfDnJjUmO7TMejcdCCwCaBHDhhU1LwK4faW3qrUWQZF/gAuB5wE7g+iTbqurmkdPeCFxaVe9NcgRwGbChr5jUj8UDwXYDSdOlzxbBkcCOqrq1qn4GXAKcsOicAh7Rbh8IfKfHeNSDhbo9C11A4Mwfadr0OUZwMHDbyP5O4JmLznkT8D+TvAZ4GHDUUm+UZAuwBWD9+vWrHqi6W/zXv3V7pOk36TLUJwMXV9UhwLHAh5M8IKaqmq+quaqaW7du3diD1H1G+//hvjEAk4A0vfpsEdwOHDqyf0h7bNTpwNEAVXVtkocABwF39BiX9oDTQKXZ1WeL4Hrg8CSHJdkfOAnYtuicbwPPBUjyFOAhwJ09xqQ9NJoE7P+XZktvLYKqujfJGcAVwL7ARVV1U5LzgO1VtQ14PfD+JK+lGTg+raqqr5i0Z+bnm7GATZtsCUizqNcbyqrqMpopoaPHzh3Zvhl4dp8xqLvl6gEtDAjbEpBm06QHi7WGLB4IXuCAsDTbLDEhwO4fachMBAO3eEUwu3+k4TERDJwrgkkyEcj7AqSBc7BYkgbORDBQ8/OwefPSs4QkDYtdQwOzeHDYBWMkmQgGxsFhSYuZCAbIwWFJoxwjGICF8QDHBCQtxRbBDFpu8ZhNm6weKumBTARTaLnicAtGv/gXfjoeIGk5JoIpstSMn6X4xS9pd5gIpsByUz79ope0GkwEU8Apn5L6ZCJY4ywPLalvTh9d4xYGhZ3pI6kvJoIpsGmT3UGS+mMikKSBMxFI0sCZCCRp4FZMBEmekOTB7fbmJGcmeWTvkUmSxqJLi+AvgV8keSIwDxwK7KLAgSRpmnRJBL+sqnuBFwJ/XlVnAY/tNyxJ0rh0SQQ/T3Iy8BLgU+2xB/UXkiRpnLokgpcCzwL+pKq+keQw4MP9hiVJGpcVS0xU1c1J3gCsb/e/AZzfd2CSpPHoMmvoBcANwGfa/Y1JtvUc1+AtrCrmimKS+tal6NybgCOBqwCq6oYkj+8xpkFbruS0JPWlSyL4eVXdnWT02C+7vHmSo4H/BuwL/PeqeusS57yIJtkU8HdVNcivPdcckDQpXRLBTUlOAfZNcjhwJvD5lV6UZF/gAuB5wE7g+iTbqurmkXMOB/4QeHZV/TDJY/bkImaBaw5ImpQuieA1wDnAT2luJLsC+K8dXncksKOqbgVIcglwAnDzyDkvBy6oqh8CVNUd3UOfPRs3uuaApPHrkgieXFXn0CSD3XEwcNvI/k7gmYvOeRJAkmtouo/eVFWfWfxGSbYAWwDWr1+/m2FIknaly30Eb0/ytSRvTvLUVf78/YDDgc3AycD7l6pjVFXzVTVXVXPr1q1b5RAkadhWTARV9RzgOcCdwIVJvpLkjR3e+3aaukQLDmmPjdoJbKuqn7f3J/w9TWIYlIXlKCVpEjqVoa6q71XVu4H/RHNPwbkdXnY9cHiSw5LsD5wELL7/4K9pWgMkOYimq+jWLjHNgoV7BV7ximbfaaKSJqHLDWVPSfKmJF8B/pxmxtAhK72uLVR3Bs3g8teAS6vqpiTnJTm+Pe0K4K4kNwNXAmdV1V17eC1TZ3Sm0IUXOlNI0mSkqnZ9QnIt8DGaL/LvjCWqXZibm6vt27dPOoxVsXlz89OZQpL6luRLVTW31HNdag09a/VDkiStFcsmgiSXVtWL2i6h0WZDgKqqp/UenSSpd7tqEfx++/O4cQQiSZqMZQeLq+q77earqupbow/gVeMJbzZZWVTSWtJl+ujzljh2zGoHMgSj00WvvropKeGUUUmTtqsxglfS/OX/+CQ3jjx1AHBN34HNIgvLSVqLdjVGsBW4HHgLcPbI8Xuq6ge9RjXDLCwnaa3ZVSKoqvpmklcvfiLJPzMZSNJsWKlFcBzwJZrpo6Mr0xTgKmW7YaGe0KZNk45Eku5v2URQVce1Pw8bXziza+vW5qeDw5LWmi61hp6d5GHt9qlJ3pHERQH2wKZNDhBLWnu6TB99L/DjJL8KvB74OvDhXqOaAQtTRRce3jMgaa3qskLZvVVVSU4A3lNVH0hyet+BTaOFBejh/ovQg/cMSFq7uiSCe5L8IfB7wG8k2Qd4UL9hTaeF+wQ2bvReAUnTo0sieDFwCvCyqvpeOz7wtn7Dml7eJyBp2nRZqvJ7wEeAA5McB/ykqj7Ue2SSpLHoMmvoRcAXgd8FXgR8IcmJfQcmSRqPLl1D5wD/qqruAEiyDvjfwCf6DEySNB5dpo/us5AEWnd1fJ0kaQp0aRF8JskVwEfb/RcDl/UXkiRpnLqsWXxWkt8Gfr09NF9Vf9VvWJKkcenaxfN54GrgSuDa/sKZTq44JmmadZk19B9pZg29EDgRuC7Jy/oObJqM3kjm3cOSpk2XMYKzgKdX1V0ASR5N00K4qM/Apo03kkmaVl26hu4C7hnZv6c9JkmaAV1aBDtobiL7JM2CNCcANyZ5HUBVvaPH+CRJPeuSCL7ePhZ8sv15wOqHI0katy7TR/94HIFIkibDO4QlaeBMBJI0cCYCSRq4LjeUPSnJZ5N8td1/WpI3dnnzJEcnuSXJjiRn7+K830lSSea6hy5JWg1dWgTvB/4Q+DlAVd0InLTSi5LsC1wAHAMcAZyc5IglzjsA+H3gC93DniwXppc0S7okgodW1RcXHbu3w+uOBHZU1a1V9TPgEpp7EBZ7M3A+8JMO77kmLJSUWGBpCUnTrMt9BN9P8gSam8loVyf7bofXHQzcNrK/E3jm6AlJngEcWlWfTnLWcm+UZAuwBWD9+vUdPrp/lpSQNCu6JIJXA/PAk5PcDnwDOHVvPzjJPsA7gNNWOreq5tsYmJubq739bEnSfbrcUHYrcFSSh9GsVnbPSq9p3Q4cOrJ/SHtswQHAU4GrkgD8c2BbkuOranvHz5Ak7aUVE0GScxftA1BV563w0uuBw5McRpMATgL+qSe9qu4GDhp536uAPzAJSNJ4dRks/seRxy9oZgFtWOlFVXUvcAZwBfA14NKquinJeUmO3+OIJUmrqkvX0NtH95P8Gc2X+4qq6jIWrW9cVecuc+7mLu8pSVpde3Jn8UNp+vslSTOgyxjBV2injgL7AuuAlcYHJElTosv00eNGtu8F/l/b/y9JmgG7TARtmYgrqurJY4pHkjRmuxwjqKpfALckWRu380qSVl2XrqFHATcl+SLNFFIAqsopoJI0A7okgv/SexSSpInpkgiOrao3jB5Icj5wdT8hSZLGqct9BM9b4tgxqx2IJGkylm0RJHkl8Crg8UluHHnqAOCavgOTJI3HrrqGtgKXA28BRpeZvKeqftBrVJKksVk2EbTVQe8GTh5fOJKkcduTWkOSpBliIthN8/NwtfOlJM2QLtNHRZMAtm69Lwm4WL2kWWEi6GjrVrjhBti0qUkCW7ZMOiJJWh0mghUstARuuAE2boSrrppwQJK0ykwEy1jcFbTQEpCkWWMiWIZdQZKGwkSwC3YFSRoCp49K0sCZCCRp4EwEkjRwJgJJGjgTwRIsIyFpSEwES9i6tfnpfQOShsBEsIxNm7x3QNIwmAgkaeBMBJI0cCYCSRq4XhNBkqOT3JJkR5Kzl3j+dUluTnJjks8meVyf8axkfh42b25qDEnSUPSWCJLsC1wAHAMcAZyc5IhFp30ZmKuqpwGfAP60r3i6GC037YwhSUPRZ9G5I4EdVXUrQJJLgBOAmxdOqKorR86/Dji1x3g6sdCcpKHps2voYOC2kf2d7bHlnA5cvtQTSbYk2Z5k+5133rmKIUqS1sRgcZJTgTngbUs9X1XzVTVXVXPr1q0bb3CSNOP67Bq6HTh0ZP+Q9tj9JDkKOAfYVFU/7TEeSdIS+mwRXA8cnuSwJPsDJwHbRk9I8nTgQuD4qrqjx1gkScvoLRFU1b3AGcAVwNeAS6vqpiTnJTm+Pe1twMOBjye5Icm2Zd5OktSTXpeqrKrLgMsWHTt3ZPuoPj9fkrSyNTFYLEmaHBMB3lEsadhMBHhHsaRh63WMYJp4R7GkobJFIEkDN9hEsDAu4NiApKEbbCJYGBcAxwYkDdugxwgcF5CkAbcIJEkNE4EkDZyJQJIGzkQgSQNnIpCkgTMRSNLAmQgkaeBMBJI0cINLBJaclqT7G1wisOS0JN3fIEtMWFpCku4zmBaBXUKStLTBJAK7hCRpaYPqGrJLSJIeaDAtAknS0kwEkjRwJgJJGjgTgSQNnIlAkgbORCBJA2cikKSBMxFI0sCZCCRp4HpNBEmOTnJLkh1Jzl7i+Qcn+Vj7/BeSbOgzHknSA/WWCJLsC1wAHAMcAZyc5IhFp50O/LCqngi8Ezi/r3gkSUvrs0VwJLCjqm6tqp8BlwAnLDrnBOCD7fYngOcmSY8xSZIW6bPo3MHAbSP7O4FnLndOVd2b5G7g0cD3R09KsgXYArB+/fo9Cmbjxj16mSTNvKmoPlpV88A8wNzcXO3Je7zrXasZkSTNjj67hm4HDh3ZP6Q9tuQ5SfYDDgTu6jEmSdIifSaC64HDkxyWZH/gJGDbonO2AS9pt08E/qaq9ugvfknSnumta6jt8z8DuALYF7ioqm5Kch6wvaq2AR8APpxkB/ADmmQhSRqjXscIquoy4LJFx84d2f4J8Lt9xiBJ2jXvLJakgTMRSNLAmQgkaeBMBJI0cJm22ZpJ7gS+tYcvP4hFdy0PgNc8DF7zMOzNNT+uqtYt9cTUJYK9kWR7Vc1NOo5x8pqHwWsehr6u2a4hSRo4E4EkDdzQEsH8pAOYAK95GLzmYejlmgc1RiBJeqChtQgkSYuYCCRp4GYyESQ5OsktSXYkOXuJ5x+c5GPt819IsmECYa6qDtf8uiQ3J7kxyWeTPG4Sca6mla555LzfSVJJpn6qYZdrTvKi9nd9U5Kt445xtXX4b3t9kiuTfLn97/vYScS5WpJclOSOJF9d5vkkeXf773Fjkmfs9YdW1Uw9aEpefx14PLA/8HfAEYvOeRXwvnb7JOBjk457DNf8HOCh7fYrh3DN7XkHAJ8DrgPmJh33GH7PhwNfBh7V7j9m0nGP4ZrngVe220cA35x03Ht5zb8JPAP46jLPHwtcDgT4NeALe/uZs9giOBLYUVW3VtXPgEuAExadcwLwwXb7E8Bzk2SMMa62Fa+5qq6sqh+3u9fRrBg3zbr8ngHeDJwP/GScwfWkyzW/HLigqn4IUFV3jDnG1dblmgt4RLt9IPCdMca36qrqczTrsyznBOBD1bgOeGSSx+7NZ85iIjgYuG1kf2d7bMlzqupe4G7g0WOJrh9drnnU6TR/UUyzFa+5bTIfWlWfHmdgPerye34S8KQk1yS5LsnRY4uuH12u+U3AqUl20qx/8prxhDYxu/v/+4qmYvF6rZ4kpwJzwKZJx9KnJPsA7wBOm3Ao47YfTffQZppW3+eS/EpV/cMkg+rZycDFVfX2JM+iWfXwqVX1y0kHNi1msUVwO3DoyP4h7bElz0myH01z8q6xRNePLtdMkqOAc4Djq+qnY4qtLytd8wHAU4GrknyTpi9125QPGHf5Pe8EtlXVz6vqG8Df0ySGadXlmk8HLgWoqmuBh9AUZ5tVnf5/3x2zmAiuBw5PcliS/WkGg7ctOmcb8JJ2+0Tgb6odhZlSK15zkqcDF9IkgWnvN4YVrrmq7q6qg6pqQ1VtoBkXOb6qtk8m3FXR5b/tv6ZpDZDkIJquolvHGONq63LN3waeC5DkKTSJ4M6xRjle24D/0M4e+jXg7qr67t684cx1DVXVvUnOAK6gmXFwUVXdlOQ8YHtVbQM+QNN83EEzKHPS5CLeex2v+W3Aw4GPt+Pi366q4ycW9F7qeM0zpeM1XwE8P8nNwC+As6pqalu7Ha/59cD7k7yWZuD4tGn+wy7JR2mS+UHtuMcfAQ8CqKr30YyDHAvsAH4MvHSvP3OK/70kSatgFruGJEm7wUQgSQNnIpCkgTMRSNLAmQgkaeBMBJpaSc5M8rUkH9nFOZuTfGqccS0nyfEL1TOT/LskR4w8d157w580dk4f1dRK8n+Bo6pq5y7O2Qz8QVUdN664ukhyMfCpqvrEpGORbBFoKiV5H01p4suTvDbJkUmubWvSfz7Jv1jiNZuS3NA+vpzkgPb4WUmub2u7//Eyn/ejJO9sa/x/Nsm69vjGtrjbjUn+Ksmj2uNn5r71Hy5pj52W5D1J/jVwPPC2NpYnJLk4yYlt7f2Pj3zuP7Vokjy/vca/TfLxJA9vj7915LP+bDX/nTUQk6697cPHnj6AbwIHtduPAPZrt48C/rLd3kzzlzfA/wCe3W4/nObO+ufT1LMPzR9GnwJ+c4nPKuDft9vnAu9pt28ENrXb5wHvare/Azy43X5k+/O0kdddDJw48v4X05Q72Y+mZMLD2uPvBU6lqZ3zuZHjb2jjeDRwC/e17h856d+Lj+l72CLQrDiQpnzGV4F3Av9yiXOuAd6R5EyaL8x7aRLB82kWc/lb4MksXaTtl8DH2u2/AH49yYHt+1zdHv8gzaIi0CSIj7TVXu/tehFtTJ8BXtAWRPwt4JM0RfOOAK5JcgNNrazH0ZRQ/wnwgSS/TVNyQNotM1drSIP1ZuDKqnphmqVHr1p8QlW9Ncmnaeq0XJPk39K0BN5SVRfu5uetNLj2WzRJ4QXAOUl+ZTfe+xLgDJo6WNur6p40BaL+V1WdvPjkJEfSFF07sX3dv9mNz5JsEWhmHMh9pXhPW+qEJE+oqq9U1fk0VS2fTFPM7GUj/e0HJ3nMEi/fh+aLFuAU4P9U1d3AD5P8Rnv894Cr06yFcGhVXUnThXMgTVfUqHtoSmUv5WqapQpfTpMUoKme+uwkT2zjfFiSJ7VxH1hVlwGvBX51mfeUlmWLQLPiT4EPJnkjsNyKZP85yXNounluAi6vqp+2pYuvbauy/oimT35xqe5/BI5s3/8O4MXt8ZcA70vyUJpyzy+lqZL5F23XUYB3V9U/5P6roV5CUzHzTO5LMABU1S/aAeLT2venqu5Mchrw0SQPbk99I01C+WSSh7Sf9boV/6WkRZw+KnWQ5EdVtfivemkm2DUkSQNni0CSBs4WgSQNnIlAkgbORCBJA2cikKSBMxFI0sD9f5ATdNHg466VAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_chart(probs, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_bert(data):\n",
    "\n",
    "    input_ids = list()\n",
    "    attention_masks = list()\n",
    "\n",
    "    for s in data:\n",
    "\n",
    "        encoded = tokenizer.encode_plus(text=clean(s),\n",
    "                                        add_special_tokens=True,        \n",
    "                                        max_length=max_len, \n",
    "                                        pad_to_max_length=True, \n",
    "                                        return_attention_mask=True \n",
    "                                        )\n",
    "        \n",
    "        input_ids.append(encoded.get('input_ids'))\n",
    "        attention_masks.append(encoded.get('attention_mask'))\n",
    "\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = np.concatenate([train_data.tweet.values, test_data.tweet.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "data_encoded = [tokenizer.encode(s, add_special_tokens=True) for s in all_data]\n",
    "max_len = max([len(s) for s in data_encoded])\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 64\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "train_inputs, train_masks = prepare_for_bert(X_train)\n",
    "valid_inputs, valid_masks = prepare_for_bert(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = torch.tensor(y_train)\n",
    "valid_labels = torch.tensor(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train)\n",
    "train_dataloader = DataLoader(train, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "valid = TensorDataset(valid_inputs, valid_masks, valid_labels)\n",
    "valid_sampler = SequentialSampler(valid)\n",
    "valid_dataloader = DataLoader(valid, sampler=valid_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, freeze_bert=False):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        self.classifier = torch.nn.Sequential(torch.nn.Linear(768, 50),\n",
    "                                                torch.nn.ReLU(),\n",
    "                                                torch.nn.Linear(50, 2)\n",
    "                                                )\n",
    "\n",
    "        if freeze_bert:\n",
    "            \n",
    "            for param in self.bert.parameters():\n",
    "                \n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask\n",
    "                           )\n",
    "        \n",
    "        last_hs = outputs[0][:, 0, :]\n",
    "        res = self.classifier(last_hs)\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_model(n_epochs=2):\n",
    "\n",
    "    bert_classifier = BertClassifier(freeze_bert=False)\n",
    "    bert_classifier.to(device)\n",
    "    optimizer = AdamW(bert_classifier.parameters(),\n",
    "                      lr=5e-5,  \n",
    "                      eps=1e-8  \n",
    "                      )\n",
    "\n",
    "    total_steps = len(train_dataloader)*n_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "    \n",
    "    return bert_classifier, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_cel = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, val_dataloader=None, n_epochs=2, evaluation=False):\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        print('Epoch: ', epoch)\n",
    "\n",
    "        total_loss = 0\n",
    "        batch_loss = 0 \n",
    "        batch_counts = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for i, batch in enumerate(train_dataloader):\n",
    "            \n",
    "            batch_counts +=1\n",
    "            input_ids, mask, labels = tuple(t.to(device) for t in batch)\n",
    "            model.zero_grad()\n",
    "            logits = model(input_ids, mask)\n",
    "            loss = loss_cel(logits, labels)\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        loss_avg = total_loss / len(train_dataloader)\n",
    "\n",
    "        print('Loss: ', loss_avg)\n",
    "        \n",
    "        if evaluation == True:\n",
    "\n",
    "            valid_loss, valid_accuracy = evaluate(model, valid_dataloader)\n",
    "            print('Evaluation')\n",
    "            print('valid_loss: ', valid_loss)\n",
    "    \n",
    "    print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, valid_dataloader):\n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = list()\n",
    "    valid_acc = list()\n",
    "    \n",
    "    for i in valid_dataloader:\n",
    "        \n",
    "        input_ids, mask, labels = tuple(t.to(device) for t in i)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            logits = model(input_ids, mask)\n",
    "\n",
    "        loss = loss_cel(logits, labels)\n",
    "        valid_loss.append(loss.item())\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "        acc = (preds == labels).cpu().numpy().mean()*100\n",
    "        valid_acc.append(acc)\n",
    "\n",
    "    valid_loss = np.mean(valid_loss)\n",
    "    valid_accuracy = np.mean(valid_acc)\n",
    "\n",
    "    return valid_loss, valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Loss:  0.5425929799675941\n",
      "Evaluation\n",
      "valid_loss:  0.4561811008236625\n",
      "Epoch:  1\n",
      "Loss:  0.30389362045874196\n",
      "Evaluation\n",
      "valid_loss:  0.4575255540284244\n",
      "Epoch:  2\n",
      "Loss:  0.13721687434008345\n",
      "Evaluation\n",
      "valid_loss:  0.5970899218862707\n",
      "Epoch:  3\n",
      "Loss:  0.07663019511771078\n",
      "Evaluation\n",
      "valid_loss:  0.8320040757005865\n",
      "Epoch:  4\n",
      "Loss:  0.039442358756787144\n",
      "Evaluation\n",
      "valid_loss:  1.1285038915547458\n",
      "Epoch:  5\n",
      "Loss:  0.017609882019314682\n",
      "Evaluation\n",
      "valid_loss:  1.1372669501738115\n",
      "Epoch:  6\n",
      "Loss:  0.007967537039803574\n",
      "Evaluation\n",
      "valid_loss:  1.0703445049849423\n",
      "Epoch:  7\n",
      "Loss:  0.004641239739915666\n",
      "Evaluation\n",
      "valid_loss:  1.1517843360250646\n",
      "Epoch:  8\n",
      "Loss:  0.005498054769608037\n",
      "Evaluation\n",
      "valid_loss:  1.1090383367104963\n",
      "Epoch:  9\n",
      "Loss:  0.002252053226281229\n",
      "Evaluation\n",
      "valid_loss:  1.1405891532247716\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "random.seed(234)\n",
    "np.random.seed(234)\n",
    "torch.manual_seed(234)\n",
    "torch.cuda.manual_seed_all(234)\n",
    "\n",
    "bert_classifier, optimizer, scheduler = lang_model(n_epochs=10)\n",
    "train_model(bert_classifier, train_dataloader, valid_dataloader, n_epochs=10, evaluation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, test_dataloader):\n",
    "\n",
    "    model.eval()\n",
    "    logits = list()\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        \n",
    "        input_ids, mask = tuple(t.to(device) for t in batch)[:2]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logs = model(input_ids, mask)\n",
    "            \n",
    "        logits.append(logs)\n",
    "    \n",
    "    logits = torch.cat(logits, dim=0)\n",
    "    probs = torch.nn.functional.softmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8783203463203464\n",
      "Accuracy:  0.7970588235294118\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "probs = prediction(bert_classifier, valid_dataloader)\n",
    "\n",
    "evaluate_chart(probs, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = torch.utils.data.ConcatDataset([train, valid])\n",
    "full_train_sampler = RandomSampler(full_train)\n",
    "full_train_dataloader = DataLoader(full_train, sampler=full_train_sampler, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Loss:  0.5430919764754928\n",
      "Epoch:  1\n",
      "Loss:  0.29742680190601084\n",
      "Epoch:  2\n",
      "Loss:  0.16739220758813006\n",
      "Epoch:  3\n",
      "Loss:  0.09816992349887842\n",
      "Epoch:  4\n",
      "Loss:  0.058301511847318334\n",
      "Epoch:  5\n",
      "Loss:  0.04117813908329634\n",
      "Epoch:  6\n",
      "Loss:  0.021417608323602753\n",
      "Epoch:  7\n",
      "Loss:  0.013281274036391177\n",
      "Epoch:  8\n",
      "Loss:  0.011258918097869398\n",
      "Epoch:  9\n",
      "Loss:  0.008665517481722843\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "bert_classifier, optimizer, scheduler = lang_model(n_epochs=10)\n",
    "train_model(bert_classifier, full_train_dataloader, n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "test_inputs, test_masks = prepare_for_bert(test_data.tweet)\n",
    "test_dataset = TensorDataset(test_inputs, test_masks)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = prediction(bert_classifier, test_dataloader)\n",
    "threshold = 0.9\n",
    "preds = np.where(probs[:, 1] > threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@DeltaAssist can no longer login using email address, looking for assistance please',\n",
       " 'We had the most amazing customer service from @LANAirlinesUSA when we flew to Peru. Today I had to talk to @JetBlue and ugh, back to reality',\n",
       " '@DeltaAssist can I switch to an earlier flight tomorrow at no cost?',\n",
       " \"@gegrove @VirginAmerica Never flown them, but it's why I fly Jet Blue almost exclusively. Best customer service period.\",\n",
       " 'Back in #Chicago! Oh, how I have missed you... @ChooseChicago @enjoyillinois @AmericanAir #ttot #travel http://t.co/c1SYW42QfB',\n",
       " '_ @VirginAmerica _ Do you look better on the red carpet or the mechanical bull? Vote for your party...: Do you... http://t.co/5LTIu68ZZi',\n",
       " '@TommyFlanagan @AmericanAir hot all day long sweetheart! Tommy you stole my heart at Cape Fear Harley Davidson!',\n",
       " 'After this weekend, @United Airlines could become the official carrier of @KJMacDonald in 2015. I already miss sleeping in first class. :-)',\n",
       " '@AmericanAir are all flights to Ord from den still on schedule for tomorrow I.e not cancelled ?',\n",
       " \"@AmericanAir doesn't have staff that recognize how to prioritize passengers with immediate issues and baggage issues!\"]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = test_data[preds==1]\n",
    "list(output.sample(10).tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что наша модель справляется примерно на 7 процентов лучше бейзлайна. Судя по туториалам, которые находила в процессе подготовки, это далеко не предел возможностей, и более тщательным файнтюнингом можно добиться большего.\n",
    "Из примеров твитов, характеризованных как положительные, видно, что некоторые твиты сложно однозначно характеризовать как позитивные или негативные, однако большинство из них все равно предсказаны верно.\n",
    "\n",
    "Среди сложностей, с которыми столкнулась во время работы, хочется отметить проблему с данными, о которой писала ранее — ошибка RuntimeError: CUDA error: device-side assert triggered появлялась, когда лейблов было более чем два, а также не очень большое количество примеров использования transfer learning именно в отношении текстов, а не изображений. Зато в начале работы попробовала применить один из предложенных в таком туториале метод transfer learning для дообучения модели, тренированной на ImageNet, на датасетах с собаками и кошками и осами и пчелами. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
